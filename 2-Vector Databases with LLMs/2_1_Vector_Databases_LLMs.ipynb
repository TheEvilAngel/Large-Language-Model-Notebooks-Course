{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/peremartra/Large-Language-Model-Notebooks-Course/blob/main/2-Vector%20Databases%20with%20LLMs/2_1_Vector_Databases_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vPA--nKMhoQ"
   },
   "source": [
    "<div>\n",
    "    <h1>Large Language Models Projects</a></h1>\n",
    "    <h3>Apply and Implement Strategies for Large Language Models</h3>\n",
    "    <h2>2.1-Vector Databases with LLMs</h2>\n",
    "</div>\n",
    "\n",
    "by [Pere Martra](https://www.linkedin.com/in/pere-martra/)\n",
    "__________\n",
    "Models: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
    "\n",
    "Colab environment: CPU.\n",
    "\n",
    "Keys:\n",
    "* Vector Database.\n",
    "* ChromaDB.\n",
    "* RAG\n",
    "* Embeddings.\n",
    "\n",
    "Article related: [Harness the Power of Vector Databases: Influencing Language Models with Personalized Information.](https://medium.com/towards-artificial-intelligence/harness-the-power-of-vector-databases-influencing-language-models-with-personalized-information-ab2f995f09ba)\n",
    "__________\n",
    "\n",
    "\n",
    "If you are executing this notebook on Colab you will need a High RAM capacity environment, depending on the model used.\n",
    "\n",
    "If you don't have a Colab Pro acount you can execute this notebook on kaggle, since you will get more memory from the free tier.\n",
    "\n",
    "Here yo have a version of this notebook, that uses a Dolly 3B model, that can be executed on Kaggle: [Vector Databases with LLMs-Kaggle Version](https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/2-Vector%20Databases%20with%20LLMs/how-to-use-a-embedding-database-with-a-llm-from-hf.ipynb)\n",
    "__________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnSqcL5iOMV-"
   },
   "source": [
    "In this notebook you will see how to use an embedding database to store the information that you want to pass to a large language model so that it takes it into account in its responses.\n",
    "\n",
    "The information could be your own documents, or whatever was contained in a business knowledge database.\n",
    "\n",
    "I have prepared the notebook so that it can work with three different Kaggle datasets, so that it is easy to carry out different tests with different Datasets.\n",
    "\n",
    "![RAG Structure](https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_2-7.jpg?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDIwyhl5TTGZ"
   },
   "source": [
    "#Import Libraries.\n",
    "To start is necessaryto install some Python packages.\n",
    "\n",
    "* **sentence transformers**. This library is necessary to transform the sentences into fixed-length vectors, also know as embeddings.\n",
    "\n",
    "* **chromadb**. This is our vector Database. ChromaDB is easy to use and open source, maybe the most used Vector Database used to store embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hCD18oMGXI2p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers==4.41.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jMtUKHm6YL5T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentence-transformers==2.2.2\n",
    "#!pip install -q xformers==0.0.23\n",
    "!pip install -q chromadb==0.4.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN_QB7NmYZFj"
   },
   "source": [
    "I'm sure that you know the next two packages: Numpy and Pandas, maybe the most used python libraries.\n",
    "\n",
    "Numpy is a powerful library for numerical computing.\n",
    "\n",
    "Pandas is a library for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VuDXjIjAYgXm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAPpMqfWYivc"
   },
   "source": [
    "# Load the Dataset\n",
    "As you will see the notebook is ready to work with three different Datasets. Just uncomment the lines of the Dataset you want to use.\n",
    "\n",
    "I selected Datasets with News. Two of them have just a brief decription of the new, but the other contains the full text.\n",
    "\n",
    "As you are working in a memory limited environment, and you can use just a few gb of memory I limited the number of news to use with the variable MAX_NEWS.\n",
    "\n",
    "The name of the field containing the text of the new is stored in the variable *DOCUMENT* and the metadata in *TOPIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYWQlIo0FzNO"
   },
   "source": [
    "# Copy Kaggle Dataset\n",
    "I used the kotartemiy/topic-labeled-news-dataset 此处只用了这个数据集\n",
    "https://www.kaggle.com/datasets/kotartemiy/topic-labeled-news-dataset\n",
    "\n",
    "Artem Burgara. (2020). R vs. Python: Topic Labeled News Dataset, . Retrieved December 2023, from https://www.kaggle.com/discussions/general/46091.\n",
    "\n",
    "But you can ose other datasets, I encourage you to try at least one of these:\n",
    "* https://www.kaggle.com/datasets/gpreda/bbc-news\n",
    "* https://www.kaggle.com/datasets/deepanshudalal09/mit-ai-news-published-till-2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJaT5EwlitXg",
    "outputId": "2831c0de-927c-417a-f343-8da83cb72015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0U9BXNKBi9lR",
    "outputId": "8e18ddc5-9de5-41ee-8ccd-2e25642f05be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from kaggle) (4.67.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/python/3.12.1/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in /home/codespace/.local/lib/python3.12/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /home/codespace/.local/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kaggle) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GCzM-FdBjHtH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#This directory should contain you kaggle.json file with you key\n",
    "# os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = '/workspaces/Large-Language-Model-Notebooks-Course'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ynM9bwdjDyh",
    "outputId": "a5ee39d4-2276-4175-99df-bf588f04b72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /workspaces/Large-Language-Model-Notebooks-Course/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/kotartemiy/topic-labeled-news-dataset\n",
      "License(s): CC0-1.0\n",
      "Downloading topic-labeled-news-dataset.zip to /workspaces/Large-Language-Model-Notebooks-Course/2-Vector Databases with LLMs\n",
      "100%|██████████████████████████████████████| 9.45M/9.45M [00:01<00:00, 11.3MB/s]\n",
      "100%|██████████████████████████████████████| 9.45M/9.45M [00:01<00:00, 6.48MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d kotartemiy/topic-labeled-news-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GCSzcqOIjlae"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Define the path to your zip file\n",
    "# file_path = '/content/topic-labeled-news-dataset.zip'\n",
    "file_path = '/workspaces/Large-Language-Model-Notebooks-Course/2-Vector Databases with LLMs/topic-labeled-news-dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aUdl7-iqkttN"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/workspaces/Large-Language-Model-Notebooks-Course/kaggle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mie-ryBHL9dJ"
   },
   "source": [
    "#Loading the Dataset\n",
    "\n",
    "Although I've utilized a single dataset for the notebook, I've set it up to facilitate testing with different datasets, available on Kaggle.\n",
    "\n",
    "I selected Datasets with News. Two of them have just a brief decription of the new, but the other contains the full text.\n",
    "\n",
    "As we are working in a free and limited space, and we can use just 30 gb of memory I limited the number of news to use with the variable MAX_NEWS.\n",
    "\n",
    "The name of the field containing the text of the new is stored in the variable DOCUMENT and the metadata in TOPIC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MeeuZ7tbPrjR"
   },
   "outputs": [],
   "source": [
    "news = pd.read_csv('/workspaces/Large-Language-Model-Notebooks-Course/kaggle/labelled_newscatcher_dataset.csv', sep=';')\n",
    "MAX_NEWS = 1000\n",
    "DOCUMENT=\"title\"\n",
    "TOPIC=\"topic\"\n",
    "\n",
    "#Just in case you want to try with a different Dataset.\n",
    "#news = pd.read_csv('/content/drive/MyDrive/kaggle/bbc_news.csv')\n",
    "#MAX_NEWS = 1000\n",
    "#DOCUMENT=\"description\"\n",
    "#TOPIC=\"title\"\n",
    "\n",
    "#news = pd.read_csv('/content/drive/MyDrive/kaggle/mit-ai-news-published-till-2023/articles.csv')\n",
    "#MAX_NEWS = 100\n",
    "#DOCUMENT=\"Article Body\"\n",
    "#TOPIC=\"Article Header\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGy3ZO4MMY7t"
   },
   "source": [
    "ChromaDB requires that the data has a unique identifier. You can achieve it with the statement below, which will create a new column called **Id**. 结尾多了1列变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "BPhCplVecPK6",
    "outputId": "31901f90-6717-429e-c94a-f34187f9ed76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
       "      <td>eurekalert.org</td>\n",
       "      <td>2020-08-06 13:59:45</td>\n",
       "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
       "      <td>pulse.ng</td>\n",
       "      <td>2020-08-12 15:14:19</td>\n",
       "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.express.co.uk/news/science/1322607...</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>2020-08-13 21:01:00</td>\n",
       "      <td>Artificial intelligence warning: AI will know ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                               link          domain  \\\n",
       "0  SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...  eurekalert.org   \n",
       "1  SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...        pulse.ng   \n",
       "2  SCIENCE  https://www.express.co.uk/news/science/1322607...   express.co.uk   \n",
       "\n",
       "        published_date                                              title  \\\n",
       "0  2020-08-06 13:59:45  A closer look at water-splitting's solar fuel ...   \n",
       "1  2020-08-12 15:14:19  An irresistible scent makes locusts swarm, stu...   \n",
       "2  2020-08-13 21:01:00  Artificial intelligence warning: AI will know ...   \n",
       "\n",
       "  lang  id  \n",
       "0   en   0  \n",
       "1   en   1  \n",
       "2   en   2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[\"id\"] = news.index\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "elYy8a0OTJaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Because it is just a example we select a small portion of News.\n",
    "subset_news = news.head(MAX_NEWS)\n",
    "subset_news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8tDSbZ3MxZP"
   },
   "source": [
    "# Import and configure the Vector Database\n",
    "You are going to use ChromaDB, the most popular OpenSource embedding Database.\n",
    "\n",
    "First you need to import ChromaDB, and after that import the **Settings** class from **chromadb.config** module. This class allows to change the setting for the ChromaDB system, and customize its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cXYYHBJzMl5n"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Settings\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/__init__.py:79\u001b[0m\n\u001b[1;32m     77\u001b[0m             sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpysqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     80\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91mYour system has an unsupported version of sqlite3. Chroma \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124m                    requires sqlite3 >= 3.35.0.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[94mPlease visit \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124m                    https://docs.trychroma.com/troubleshooting#sqlite to learn how \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124m                    to upgrade.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m             )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override Chroma's default settings, environment variables or .env files\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmFsTy9XOPla"
   },
   "source": [
    "Now you need to create the seetings object calling the Settings function imported previously. The object is stored in the variable **settings_chroma**.\n",
    "\n",
    "You need to inform two parameters\n",
    "\n",
    "* **chroma_db_impl**. Here you must specify the database implementation and the format how store the data. I choose **duckdb**, because his high-performace. It operate primarly in memory. And is fully compatible with SQL. The store format **parquet** is good for tabular data. With good compression rates and performance.\n",
    "\n",
    "* **persist_directory**: It just contains the directory where the data will be stored. Is possible work without a directory and the data will be stored in memory without persistece, but some cloud providers or platforms like Kaggle dosn't support that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAbROIjCONv7"
   },
   "outputs": [],
   "source": [
    "#OLD VERSION\n",
    "#settings_chroma = Settings(chroma_db_impl=\"duckdb+parquet\",\n",
    "#                          persist_directory='./input')\n",
    "#chroma_client = chromadb.Client(settings_chroma)\n",
    "\n",
    "#NEW VERSION => 0.40\n",
    "chroma_client = chromadb.PersistentClient(path=\"/content/drive/MyDrive/chromadb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxlh6QfiSK-p"
   },
   "source": [
    "# Filling and Querying the ChromaDB Database\n",
    "The Data in ChromaDB is stored in collections. If the collection previously exist is necessary to delete it.\n",
    "\n",
    "In the next lines, the collection is created by calling the ***create_collection*** function in the ***chroma_client*** created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4O2UuGzW5mC"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HOnr43oO1vG"
   },
   "outputs": [],
   "source": [
    "collection_name = \"news_collection\"+datetime.now().strftime(\"%s\")\n",
    "if len(chroma_client.list_collections()) > 0 and collection_name in [chroma_client.list_collections()[0].name]:\n",
    "        chroma_client.delete_collection(name=collection_name)\n",
    "\n",
    "collection = chroma_client.create_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-_0xWxQSfwv"
   },
   "source": [
    "It's time to add the data to the collection. Using the function ***add*** you should inform, at least ***documents***, ***metadatas*** and ***ids***.\n",
    "* In the **document** the full news text is stored, remember that it is contained in a different column for each Dataset.\n",
    "* In **metadatas**, we can inform a list of topics.\n",
    "* In **id** an unique identificator for each row must be informed. It MUST be unique! I'm creating the ID using the range of MAX_NEWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xuAz6R0gSZho",
    "outputId": "a47379c8-e4a5-49fd-c055-f7be35196ca0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:03<00:00, 21.7MiB/s]\n"
     ]
    }
   ],
   "source": [
    "collection.add(\n",
    "    documents=subset_news[DOCUMENT].tolist(),\n",
    "    metadatas=[{TOPIC: topic} for topic in subset_news[TOPIC].tolist()],\n",
    "    ids=[f\"id{x}\" for x in range(MAX_NEWS)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpofynmFTCKm",
    "outputId": "8fb85c27-3993-4703-970b-a130bb69290a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id173', 'id829', 'id117', 'id535', 'id141', 'id218', 'id390', 'id273', 'id56', 'id900']], 'distances': [[0.8593594431877136, 1.0294400453567505, 1.0793331861495972, 1.093001127243042, 1.1329681873321533, 1.2130440473556519, 1.214331865310669, 1.2164140939712524, 1.2220635414123535, 1.2754170894622803]], 'metadatas': [[{'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}, {'topic': 'TECHNOLOGY'}]], 'embeddings': None, 'documents': [['The Legendary Toshiba is Officially Done With Making Laptops', '3 gaming laptop deals you can’t afford to miss today', 'Lenovo and HP control half of the global laptop market', 'Asus ROG Zephyrus G14 gaming laptop announced in India', 'Acer Swift 3 featuring a 10th-generation Intel Ice Lake CPU, 2K screen, and more launched in India for INR 64999 (US$865)', \"Apple's Next MacBook Could Be the Cheapest in Company's History\", \"Features of Huawei's Desktop Computer Revealed\", 'Redmi to launch its first gaming laptop on August 14: Here are all the details', 'Toshiba shuts the lid on laptops after 35 years', 'This is the cheapest Windows PC by a mile and it even has a spare SSD slot']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(query_texts=[\"laptop\"], n_results=10 )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4PDwcbHcQqO"
   },
   "source": [
    "#Vector MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8s8H-49cNmb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz9rF11rcP2r"
   },
   "outputs": [],
   "source": [
    "getado = collection.get(ids=\"id141\",\n",
    "                       include=[\"documents\", \"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLJtGzfecXAO",
    "outputId": "a7388dee-201c-42d5-99a9-1742cc506301"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0808560848236084,\n",
       "  -0.049963705241680145,\n",
       "  -0.023777484893798828,\n",
       "  -0.011053602211177349,\n",
       "  0.02665771171450615,\n",
       "  -0.04479333013296127,\n",
       "  -0.02889663353562355,\n",
       "  0.026656104251742363,\n",
       "  0.0014397227205336094,\n",
       "  -0.016407841816544533,\n",
       "  0.0653492733836174,\n",
       "  -0.06901992857456207,\n",
       "  -0.05748078227043152,\n",
       "  0.010111615061759949,\n",
       "  0.05043035000562668,\n",
       "  -0.002057764446362853,\n",
       "  0.07256408035755157,\n",
       "  -0.12437368929386139,\n",
       "  0.010659442283213139,\n",
       "  -0.10942046344280243,\n",
       "  -0.01143240462988615,\n",
       "  -0.010376011952757835,\n",
       "  -0.020610831677913666,\n",
       "  -0.024394094944000244,\n",
       "  0.07828476279973984,\n",
       "  0.005820558872073889,\n",
       "  0.023317726328969002,\n",
       "  -0.08243829756975174,\n",
       "  -0.02726505883038044,\n",
       "  0.0046674772165715694,\n",
       "  0.004340188577771187,\n",
       "  0.03252805024385452,\n",
       "  -0.026030974462628365,\n",
       "  0.07963905483484268,\n",
       "  0.042182061821222305,\n",
       "  -0.12119994312524796,\n",
       "  0.04907083883881569,\n",
       "  -0.07625846564769745,\n",
       "  0.04331624507904053,\n",
       "  -0.08360457420349121,\n",
       "  -0.07140401750802994,\n",
       "  -0.018792513757944107,\n",
       "  0.036049388349056244,\n",
       "  0.042845625430345535,\n",
       "  0.025760438293218613,\n",
       "  0.03972514718770981,\n",
       "  -0.007091294974088669,\n",
       "  0.035189948976039886,\n",
       "  0.027369096875190735,\n",
       "  0.009289839304983616,\n",
       "  -0.03916166350245476,\n",
       "  -0.037401288747787476,\n",
       "  -0.03369569778442383,\n",
       "  -0.06543102860450745,\n",
       "  0.01919756457209587,\n",
       "  -0.009083813056349754,\n",
       "  0.022507958114147186,\n",
       "  -0.04346753656864166,\n",
       "  0.03663364797830582,\n",
       "  0.09003791213035583,\n",
       "  0.037535011768341064,\n",
       "  -0.04698672145605087,\n",
       "  -0.021450482308864594,\n",
       "  0.049021799117326736,\n",
       "  0.0008767120307311416,\n",
       "  -0.0491013377904892,\n",
       "  0.019651763141155243,\n",
       "  -0.11427141726016998,\n",
       "  -0.0041212718933820724,\n",
       "  -0.059363994747400284,\n",
       "  0.08288168162107468,\n",
       "  -0.015205126255750656,\n",
       "  0.05800360441207886,\n",
       "  -0.009099257178604603,\n",
       "  -0.06618720293045044,\n",
       "  -0.04995487257838249,\n",
       "  0.051422737538814545,\n",
       "  -0.030697545036673546,\n",
       "  -0.00599612295627594,\n",
       "  -0.017441147938370705,\n",
       "  -0.0067165326327085495,\n",
       "  -0.026863766834139824,\n",
       "  0.009797872975468636,\n",
       "  0.012698033824563026,\n",
       "  -0.017240023240447044,\n",
       "  -0.040722113102674484,\n",
       "  0.02619202248752117,\n",
       "  -0.036331336945295334,\n",
       "  -0.005993332713842392,\n",
       "  -0.03835161030292511,\n",
       "  -0.0025671017356216908,\n",
       "  0.017816301435232162,\n",
       "  0.015638208016753197,\n",
       "  -0.002425231970846653,\n",
       "  -0.04693610966205597,\n",
       "  0.014938564039766788,\n",
       "  0.057856056839227676,\n",
       "  -0.04266524314880371,\n",
       "  -0.051958806812763214,\n",
       "  0.07029527425765991,\n",
       "  0.0174096692353487,\n",
       "  0.01044029463082552,\n",
       "  0.06522297114133835,\n",
       "  -0.0005443890695460141,\n",
       "  -0.0072739566676318645,\n",
       "  -0.01764906942844391,\n",
       "  -0.01343501266092062,\n",
       "  0.04487789049744606,\n",
       "  -0.04048682376742363,\n",
       "  0.05065847188234329,\n",
       "  -0.006964817643165588,\n",
       "  -0.039026305079460144,\n",
       "  -0.06116586551070213,\n",
       "  0.009619001299142838,\n",
       "  -0.01937313936650753,\n",
       "  -0.07259991019964218,\n",
       "  -0.05417889729142189,\n",
       "  -0.012206215411424637,\n",
       "  0.14574117958545685,\n",
       "  0.07729611545801163,\n",
       "  -0.03489774465560913,\n",
       "  0.02000734768807888,\n",
       "  -0.00971849262714386,\n",
       "  -0.0023303572088479996,\n",
       "  -0.08877687901258469,\n",
       "  0.007430689875036478,\n",
       "  -0.022453872486948967,\n",
       "  2.939167320216669e-33,\n",
       "  -0.03226035088300705,\n",
       "  0.02646695077419281,\n",
       "  -0.06441568583250046,\n",
       "  -0.10495101660490036,\n",
       "  0.007915517315268517,\n",
       "  -0.056241028010845184,\n",
       "  0.0600648857653141,\n",
       "  0.020356711000204086,\n",
       "  0.008408062160015106,\n",
       "  0.00394280394539237,\n",
       "  -0.07579407840967178,\n",
       "  -0.059283699840307236,\n",
       "  -0.07090269774198532,\n",
       "  0.047602903097867966,\n",
       "  0.12866826355457306,\n",
       "  -0.09145348519086838,\n",
       "  -0.06453359127044678,\n",
       "  -0.022725841030478477,\n",
       "  -0.007938683032989502,\n",
       "  0.08817118406295776,\n",
       "  0.030397845432162285,\n",
       "  -0.08102215081453323,\n",
       "  -0.004711293615400791,\n",
       "  0.008305762894451618,\n",
       "  -0.008205698803067207,\n",
       "  0.044841013848781586,\n",
       "  0.003640854964032769,\n",
       "  -0.015380569733679295,\n",
       "  0.06941366195678711,\n",
       "  0.026241688057780266,\n",
       "  0.042122967541217804,\n",
       "  -0.022600207477808,\n",
       "  -0.004685663152486086,\n",
       "  -0.08609002083539963,\n",
       "  -0.0017022470710799098,\n",
       "  -0.036475248634815216,\n",
       "  0.03104810230433941,\n",
       "  -0.07396797835826874,\n",
       "  0.0006451740628108382,\n",
       "  0.057689860463142395,\n",
       "  -0.03433110564947128,\n",
       "  0.10101553797721863,\n",
       "  -0.07978133112192154,\n",
       "  -0.01770963706076145,\n",
       "  0.03582654148340225,\n",
       "  0.07763752341270447,\n",
       "  0.007194378413259983,\n",
       "  0.05085881054401398,\n",
       "  0.03166932985186577,\n",
       "  -0.050254058092832565,\n",
       "  -0.1192030981183052,\n",
       "  -0.002129735192283988,\n",
       "  -0.0107394028455019,\n",
       "  -0.048253513872623444,\n",
       "  0.05193442106246948,\n",
       "  -0.0033458012621849775,\n",
       "  0.045708633959293365,\n",
       "  -0.0063198041170835495,\n",
       "  0.13073934614658356,\n",
       "  0.05694258213043213,\n",
       "  -0.1031755656003952,\n",
       "  -0.021950311958789825,\n",
       "  -0.05125086382031441,\n",
       "  -0.006670759059488773,\n",
       "  -0.04244102165102959,\n",
       "  0.07283089309930801,\n",
       "  0.08295755833387375,\n",
       "  -0.01451050490140915,\n",
       "  -0.050436634570360184,\n",
       "  -0.0063996752724051476,\n",
       "  -0.05111794173717499,\n",
       "  -0.06090034544467926,\n",
       "  0.12017730623483658,\n",
       "  -0.007007972337305546,\n",
       "  -0.018361017107963562,\n",
       "  0.05737388879060745,\n",
       "  -0.06952648609876633,\n",
       "  -0.0329073891043663,\n",
       "  -0.046019524335861206,\n",
       "  -0.04026426374912262,\n",
       "  -0.03974202275276184,\n",
       "  0.04068472236394882,\n",
       "  0.06414211541414261,\n",
       "  0.08900655806064606,\n",
       "  -0.00060390739236027,\n",
       "  0.06864351779222488,\n",
       "  -0.04542217403650284,\n",
       "  -0.012834936380386353,\n",
       "  0.014704265631735325,\n",
       "  0.08229125291109085,\n",
       "  -0.011864698491990566,\n",
       "  -0.007569513283669949,\n",
       "  0.029478946700692177,\n",
       "  -0.017556926235556602,\n",
       "  0.03026776760816574,\n",
       "  -3.4444798318695305e-33,\n",
       "  0.013093586079776287,\n",
       "  -0.05642778053879738,\n",
       "  -0.05393407866358757,\n",
       "  0.02010548673570156,\n",
       "  0.002186316065490246,\n",
       "  0.021474365144968033,\n",
       "  -0.01675189472734928,\n",
       "  0.11519582569599152,\n",
       "  0.009137553162872791,\n",
       "  0.002790238708257675,\n",
       "  -0.028134936466813087,\n",
       "  0.08885099738836288,\n",
       "  0.07289770990610123,\n",
       "  0.02972547896206379,\n",
       "  0.03313830494880676,\n",
       "  -0.03830660134553909,\n",
       "  -0.015428598038852215,\n",
       "  -0.025887154042720795,\n",
       "  0.02991276979446411,\n",
       "  0.021465003490447998,\n",
       "  0.055984679609537125,\n",
       "  0.02411733567714691,\n",
       "  0.013602275401353836,\n",
       "  0.001853855443187058,\n",
       "  0.046712420880794525,\n",
       "  0.019653165712952614,\n",
       "  -0.0611024871468544,\n",
       "  0.006502089090645313,\n",
       "  0.0441303625702858,\n",
       "  -0.030408691614866257,\n",
       "  0.003392198821529746,\n",
       "  -0.07827484607696533,\n",
       "  0.08200996369123459,\n",
       "  0.021945785731077194,\n",
       "  -0.04214276745915413,\n",
       "  -0.011046931147575378,\n",
       "  0.11221751570701599,\n",
       "  -0.03547649085521698,\n",
       "  -0.02034923806786537,\n",
       "  0.05863974243402481,\n",
       "  0.061948224902153015,\n",
       "  0.004163042642176151,\n",
       "  0.025604233145713806,\n",
       "  0.07054829597473145,\n",
       "  0.026611244305968285,\n",
       "  0.03901861235499382,\n",
       "  -0.0028351128567010164,\n",
       "  -0.013862921856343746,\n",
       "  -0.03907373547554016,\n",
       "  -0.10136910527944565,\n",
       "  0.015273002907633781,\n",
       "  -0.0636049285531044,\n",
       "  0.009429153054952621,\n",
       "  -0.03778139874339104,\n",
       "  -0.07231791317462921,\n",
       "  -0.05598380044102669,\n",
       "  0.0146296676248312,\n",
       "  0.006302482448518276,\n",
       "  0.036601871252059937,\n",
       "  -0.07091113924980164,\n",
       "  0.03455745428800583,\n",
       "  0.021303288638591766,\n",
       "  0.018934456631541252,\n",
       "  0.01931314915418625,\n",
       "  0.007075129076838493,\n",
       "  0.018622223287820816,\n",
       "  0.05089221149682999,\n",
       "  0.03337225690484047,\n",
       "  -0.008652801625430584,\n",
       "  -0.023814190179109573,\n",
       "  -0.05765106528997421,\n",
       "  -0.10482978075742722,\n",
       "  0.013372018001973629,\n",
       "  -0.01933068409562111,\n",
       "  -0.016363972797989845,\n",
       "  0.04313588887453079,\n",
       "  -0.019315389916300774,\n",
       "  0.042876679450273514,\n",
       "  0.07228625565767288,\n",
       "  -0.004229306243360043,\n",
       "  0.025138597935438156,\n",
       "  0.07576548308134079,\n",
       "  0.033386338502168655,\n",
       "  0.022974086925387383,\n",
       "  0.07685324549674988,\n",
       "  -0.05225932598114014,\n",
       "  0.043289393186569214,\n",
       "  -0.012385099194943905,\n",
       "  -0.036590274423360825,\n",
       "  -0.012774484232068062,\n",
       "  -0.046136267483234406,\n",
       "  0.051983099430799484,\n",
       "  -0.06112852692604065,\n",
       "  -0.0003355621884111315,\n",
       "  -0.006177410017699003,\n",
       "  -2.835624535180159e-08,\n",
       "  0.06613793969154358,\n",
       "  0.011798004619777203,\n",
       "  0.037113726139068604,\n",
       "  0.04696718230843544,\n",
       "  0.043035347014665604,\n",
       "  -0.09251100569963455,\n",
       "  0.046135202050209045,\n",
       "  0.08055239915847778,\n",
       "  0.10685128718614578,\n",
       "  -0.007414942141622305,\n",
       "  -0.0413203239440918,\n",
       "  -0.08303714543581009,\n",
       "  -0.018203390762209892,\n",
       "  0.013738766312599182,\n",
       "  0.043958164751529694,\n",
       "  0.037307366728782654,\n",
       "  0.03315778449177742,\n",
       "  0.0881715714931488,\n",
       "  0.0019880577456206083,\n",
       "  -0.07271483540534973,\n",
       "  0.0230609979480505,\n",
       "  0.04958247020840645,\n",
       "  0.09864996373653412,\n",
       "  -0.09664388746023178,\n",
       "  -0.0389941930770874,\n",
       "  0.040474724024534225,\n",
       "  -0.053038567304611206,\n",
       "  0.030482791364192963,\n",
       "  0.06002917140722275,\n",
       "  0.01091479416936636,\n",
       "  -0.10208377242088318,\n",
       "  0.03962486982345581,\n",
       "  0.03992467746138573,\n",
       "  -0.08412328362464905,\n",
       "  0.09101279079914093,\n",
       "  -0.06123001500964165,\n",
       "  -0.03717247396707535,\n",
       "  -0.019029760733246803,\n",
       "  0.0963117778301239,\n",
       "  -0.02458466775715351,\n",
       "  -0.010751205496490002,\n",
       "  0.0013019784819334745,\n",
       "  -0.07538682967424393,\n",
       "  -0.018940189853310585,\n",
       "  0.054801248013973236,\n",
       "  0.003068663412705064,\n",
       "  -0.1022912859916687,\n",
       "  -0.1027493104338646,\n",
       "  0.0010229793842881918,\n",
       "  0.03838779032230377,\n",
       "  -0.03387368097901344,\n",
       "  -0.006812311243265867,\n",
       "  -0.028700852766633034,\n",
       "  0.06181854382157326,\n",
       "  0.012259316630661488,\n",
       "  0.02560870721936226,\n",
       "  -0.03962231054902077,\n",
       "  -0.06302027404308319,\n",
       "  -0.10198362916707993,\n",
       "  0.09703315049409866,\n",
       "  0.12165297567844391,\n",
       "  -0.104803167283535,\n",
       "  -0.04797930270433426,\n",
       "  0.07281223684549332]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = getado[\"embeddings\"]\n",
    "word_list = getado[\"documents\"]\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hR3SaELeccOT"
   },
   "source": [
    "Once the information is on the Database you can query It, and ask for data that matches your needs. The search is done inside the content of the document. It dosn't look for the exact word, or phrase, the results will be based on the similarity between the search terms and the content of documents.\n",
    "\n",
    "The metadata is not used in the search, but they can be utilized for filtering or refining the results after the initial search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OQoEDJ1c514"
   },
   "source": [
    "# Loading the model and creating the prompt\n",
    "TRANSFORMERS!!\n",
    "Time to use the library **transformers**, the most famous library from [hugging face](https://huggingface.co/) for working with language models.\n",
    "\n",
    "We are importing:\n",
    "* **Autotokenizer**: It is a utility class for tokenizing text inputs that are compatible with various pre-trained language models.\n",
    "* **AutoModelForCasualLLM**: it provides an interface to pre-trained language models specifically designed for language generation tasks using causal language modeling (e.g., GPT models), or the model used in this notebook ***TinyLlama-1.1B-Chat-v1.0***.\n",
    "* **pipeline**: provides a simple interface for performing various natural language processing (NLP) tasks, such as text generation (our case) or text classification.\n",
    "\n",
    "The model I have selected is [TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0), which is one of the smartest Small Language Models. Even so, it still has 1.1 billion parameters.\n",
    "\n",
    "Please, feel free to test [different Models](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending), you need to search for NLP models trained for text-generation. My recomendation is choose \"small\" models, or we will run out of memory in kaggle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lA3c0W8i_zg4"
   },
   "outputs": [],
   "source": [
    "#!pip install -q einops==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0OIjfQxc3rW"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "#model_id = \"databricks/dolly-v2-3b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Sju48Dekow"
   },
   "source": [
    "\n",
    "The next step is to initialize the pipeline using the objects created above.\n",
    "\n",
    "The model's response is limited to 256 tokens, for this project I'm not interested in a longer response, but it can easily be extended to whatever length you want.\n",
    "\n",
    "Setting ***device_map*** to ***auto*** we are instructing the model to automaticaly select the most appropiate device: CPU or GPU for processing the text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Gr-YtwXdCbI"
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=lm_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llI-0pcGjz-Y"
   },
   "source": [
    "## Creating the extended prompt\n",
    "To create the prompt you can use the result from query the Vector Database  and the sentence introduced by the user.\n",
    "\n",
    "The prompt have two parts, the **relevant context** that is the information recovered from the database and the **user's question**.\n",
    "\n",
    "You only need to join the two parts together to create the prompt sended to the model.\n",
    "\n",
    "You can limit the lenght of the context passed to the model, because you can get some Memory problems with one of the datasets that contains a realy large text in the document part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxrmUcEGjwTc"
   },
   "outputs": [],
   "source": [
    "question = \"Can I buy a new Toshiba laptop?\"\n",
    "context = \" \".join([f\"#{str(i)}\" for i in results[\"documents\"][0]])\n",
    "#context = context[0:5120]\n",
    "prompt_template = f\"\"\"\n",
    "Relevant context: {context}\n",
    "Considering the relevant context, answer the question.\n",
    "Question: {question}\n",
    "Answer: \"\"\"\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3gRd5HNkJA1"
   },
   "source": [
    "Now all that remains is to send the prompt to the model and wait for its response!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9ZiP7QekFYS"
   },
   "outputs": [],
   "source": [
    "lm_response = pipe(prompt_template)\n",
    "print(lm_response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n_ezyOdFnjQ"
   },
   "source": [
    "__________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCVJcSSzCure"
   },
   "source": [
    "# Connecting to a ChromaDB existing collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PnkBLCWFz4z"
   },
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sn4jcasik4MB"
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client_2 = chromadb.PersistentClient(path=\"/content/drive/MyDrive/chromadb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c5IlfB8mEHr"
   },
   "outputs": [],
   "source": [
    "collection2 = chroma_client_2.get_collection(name=collection_name)\n",
    "results2 = collection.query(query_texts=[\"laptop\"], n_results=10 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKhm8u77DLNu"
   },
   "outputs": [],
   "source": [
    "print(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeGJrCSEJG61"
   },
   "source": [
    "# Conclusions\n",
    "A very short notebook, but with a lot of content.\n",
    "\n",
    "You have used a vector database to store information. Then move on to retrieve it and use it to create an extended prompt that you've used to call one of the newer large language models available in Hugging Face.\n",
    "\n",
    "The model has returned a response taking into account the context that you have passed to it in the prompt.\n",
    "\n",
    "This way of working with language models is very powerful.\n",
    "\n",
    "Is possible to make the model use our information without the need for Fine Tuning. This technique really has some very big advantages over fine tuning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
